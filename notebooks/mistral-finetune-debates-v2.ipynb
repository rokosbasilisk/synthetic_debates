{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import FullyShardedDataParallelPlugin, Accelerator\n",
    "from datasets import load_dataset\n",
    "from datetime import datetime\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from peft import PeftModel, prepare_model_for_kbit_training\n",
    "from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import json\n",
    "import torch\n",
    "import transformers\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "#base_model_id = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "data_path = \"data/debates/debate_data_v2.json\"\n",
    "data_aug_path = \"data/debates/augmented_debates.json\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    padding_side=\"left\",\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dataset prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "debate_data = json.loads(open(data_path,\"r\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "debate_prefix = f\"\"\"<s>[INST] You are a debate completion agent. Given a debate transcript, your task is to continue the discourse based on the current speaker and the preceding context. The debate begins with a \"HUMAN_JUDGE,\" followed by two adversaries, Alice and Bob, who continue to argue.\n",
    "The debate's topic is: \"<TOPIC>\"\n",
    "During each turn of the debate, Alice or Bob presents concise arguments. They specify whether they are arguing for \"Yes\" or \"No\" based on the question posed in the debate.[/INST]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_debate_str(debate):\n",
    "    \n",
    "    get_role_token = lambda role_str: \"|<\" + role_str.upper() + \">|\"\n",
    "    \n",
    "    debate_str = \"\"\"|<START_DEBATE>|\"\"\"\n",
    "    for msg in debate:\n",
    "        role = get_role_token(msg[\"name\"])\n",
    "        if role!=\"|<HUMAN_JUDGE>|\":\n",
    "            debate_str += role+msg[\"content\"]+role\n",
    "    debate_str+= \"|<END_DEBATE>|\"\n",
    "    \n",
    "    return debate_str\n",
    "\n",
    "def process_debate_data(debate_data,is_aug=False):\n",
    "    \n",
    "    debates_list = []\n",
    "\n",
    "    for index, (topic, debate) in enumerate(debate_data.items()):\n",
    "        if is_aug:\n",
    "            for example in debate[\"right_examples\"]:\n",
    "                if example:\n",
    "                    transcript = debate_prefix.replace(\"<TOPIC>\",topic) + example\n",
    "                    debates_list.append({\"topic\":topic,\"transcript\":transcript})\n",
    "            \n",
    "        else:\n",
    "            transcript = debate_prefix.replace(\"<TOPIC>\",topic) + get_debate_str(debate[\"debate_messages\"])\n",
    "            debates_list.append({\"topic\":topic,\"transcript\":transcript})\n",
    "        \n",
    "    return debates_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "debates_processed = []\n",
    "\n",
    "for item in process_debate_data(debate_data):\n",
    "    json_line = json.dumps(item)\n",
    "    debates_processed.append(json_line)\n",
    "    \n",
    "with open(\"data/debates/debates_data.jsonl\", 'w') as jsonl_file:\n",
    "    for item in debates_processed:\n",
    "        jsonl_file.write(item + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17c99a27a3bf4913b8ff056af787bc84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = load_dataset('json', data_files='data/debates/debates_data.jsonl', split='train[:75]')\n",
    "eval_dataset = load_dataset('json', data_files='data/debates/debates_data.jsonl', split='train[75:]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_prompt(example):\n",
    "    \n",
    "    prompt = example[\"transcript\"]\n",
    "    result = tokenizer(prompt, truncation=True, max_length=1024, padding=\"max_length\")\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bed46e9111be47db8ee62da39986b8d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/75 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5de933d2ca04561a03cdd1d4d09d8c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(tokenize_prompt)\n",
    "tokenized_val_dataset = eval_dataset.map(tokenize_prompt)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "45524c98039a46d5b7745ad7cb638d2f"
     ]
    },
    "id": "E0Nl5mWL0k2T",
    "outputId": "47b6b01d-e9f2-4b70-919c-17ae64993843"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4b0164131e34a199c03c29cdc4df9d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(base_model_id, device_map=\"balanced\", use_safetensors=False)\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "Ybeyl20n3dYH",
    "outputId": "6a16c182-04d9-4812-ae81-502a8fe364d0"
   },
   "outputs": [],
   "source": [
    "config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=64,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        \"lm_head\",\n",
    "    ],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "c_L1131GyRgo"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1: # If more than 1 GPU\n",
    "    model.is_parallelizable = True\n",
    "    model.model_parallel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "yxSbpKQSLY6B"
   },
   "outputs": [],
   "source": [
    "fsdp_plugin = FullyShardedDataParallelPlugin(\n",
    "    state_dict_config=FullStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    "    optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    ")\n",
    "\n",
    "accelerator = Accelerator(fsdp_plugin=fsdp_plugin)\n",
    "model = accelerator.prepare_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "jq0nX33BmfaC"
   },
   "outputs": [],
   "source": [
    "project = \"debate-finetune-v2\"\n",
    "base_model_name = \"mistral\"\n",
    "run_name = base_model_name + \"-\" + project\n",
    "output_dir = \"./\" + run_name\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    args=transformers.TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        warmup_steps=500,\n",
    "        per_device_train_batch_size=8,\n",
    "        gradient_accumulation_steps=1,\n",
    "        gradient_checkpointing=True,\n",
    "        num_train_epochs=20,\n",
    "        learning_rate=2e-5, \n",
    "        bf16=True,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        logging_steps=20,              \n",
    "        logging_dir=\"./logs\",        \n",
    "        save_strategy=\"epoch\",\n",
    "        evaluation_strategy=\"epoch\", \n",
    "        do_eval=True,                \n",
    "        report_to=\"wandb\",           \n",
    "        run_name=f\"{run_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\"          \n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jq0nX33BmfaC",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/loki/anaconda3/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='133' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [133/200 11:49 < 06:02, 0.18 it/s, Epoch 13.20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.758508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.716600</td>\n",
       "      <td>1.748217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.716600</td>\n",
       "      <td>1.716491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.675300</td>\n",
       "      <td>1.655785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.675300</td>\n",
       "      <td>1.567303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.532000</td>\n",
       "      <td>1.458795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.532000</td>\n",
       "      <td>1.350491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.321900</td>\n",
       "      <td>1.261784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.321900</td>\n",
       "      <td>1.218445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.174000</td>\n",
       "      <td>1.189054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.174000</td>\n",
       "      <td>1.173349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.094600</td>\n",
       "      <td>1.164902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.094600</td>\n",
       "      <td>1.154541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./mistral-debate-finetune-v2/checkpoint-10 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "/home/loki/anaconda3/lib/python3.11/site-packages/peft/utils/save_and_load.py:134: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/loki/anaconda3/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Checkpoint destination directory ./mistral-debate-finetune-v2/checkpoint-20 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "/home/loki/anaconda3/lib/python3.11/site-packages/peft/utils/save_and_load.py:134: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/loki/anaconda3/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Checkpoint destination directory ./mistral-debate-finetune-v2/checkpoint-30 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "/home/loki/anaconda3/lib/python3.11/site-packages/peft/utils/save_and_load.py:134: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/loki/anaconda3/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Checkpoint destination directory ./mistral-debate-finetune-v2/checkpoint-40 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "/home/loki/anaconda3/lib/python3.11/site-packages/peft/utils/save_and_load.py:134: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/loki/anaconda3/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Checkpoint destination directory ./mistral-debate-finetune-v2/checkpoint-50 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "/home/loki/anaconda3/lib/python3.11/site-packages/peft/utils/save_and_load.py:134: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/loki/anaconda3/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Checkpoint destination directory ./mistral-debate-finetune-v2/checkpoint-60 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "/home/loki/anaconda3/lib/python3.11/site-packages/peft/utils/save_and_load.py:134: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/loki/anaconda3/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Checkpoint destination directory ./mistral-debate-finetune-v2/checkpoint-70 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "/home/loki/anaconda3/lib/python3.11/site-packages/peft/utils/save_and_load.py:134: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/loki/anaconda3/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Checkpoint destination directory ./mistral-debate-finetune-v2/checkpoint-80 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "/home/loki/anaconda3/lib/python3.11/site-packages/peft/utils/save_and_load.py:134: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/loki/anaconda3/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Checkpoint destination directory ./mistral-debate-finetune-v2/checkpoint-90 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "/home/loki/anaconda3/lib/python3.11/site-packages/peft/utils/save_and_load.py:134: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/loki/anaconda3/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./mistral-debate-finetune-v2/checkpoint-100 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "/home/loki/anaconda3/lib/python3.11/site-packages/peft/utils/save_and_load.py:134: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/loki/anaconda3/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Checkpoint destination directory ./mistral-debate-finetune-v2/checkpoint-110 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "/home/loki/anaconda3/lib/python3.11/site-packages/peft/utils/save_and_load.py:134: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/loki/anaconda3/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Checkpoint destination directory ./mistral-debate-finetune-v2/checkpoint-120 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "/home/loki/anaconda3/lib/python3.11/site-packages/peft/utils/save_and_load.py:134: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/loki/anaconda3/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Checkpoint destination directory ./mistral-debate-finetune-v2/checkpoint-130 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "/home/loki/anaconda3/lib/python3.11/site-packages/peft/utils/save_and_load.py:134: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/loki/anaconda3/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model.config.use_cache = False  \n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "fb8230fb86884aa6be318e2d03a88af2"
     ]
    },
    "id": "SKSnF016yRgp",
    "outputId": "bce5209d-90da-4117-c6ac-cda9f3cb3422"
   },
   "outputs": [],
   "source": [
    "ft_model = PeftModel.from_pretrained(model, \"mistral-debate-finetune-v2/checkpoint-190/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(idx):\n",
    "    \n",
    "    topic,transcript = list(debate_data.keys())[idx], get_debate_str(list(debate_data.values())[idx]['debate_messages'])\n",
    "    \n",
    "    input_prefix = debate_prefix.replace(\"<TOPIC>\",topic)+\"|<BOB>|\".join(transcript.split(\"|<BOB>|\")[:2])\n",
    "    model_input = tokenizer(input_prefix, return_tensors=\"pt\").to(\"cuda\")\n",
    "    \n",
    "    ft_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_trascript = tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=800)[0], skip_special_tokens=True)\n",
    "\n",
    "    return input_prefix, transcript, model_trascript\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    }
   ],
   "source": [
    "input_prefix, transcript, model_trascript = eval_model(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>[INST] You are a debate completion agent. Given a debate transcript, your task is to continue the discourse based on the current speaker and the preceding context. The debate begins with a \"HUMAN_JUDGE,\" followed by two adversaries, Alice and Bob, who continue to argue.\\nThe debate\\'s topic is: \"Should there be stricter regulations on the use of pesticides in agriculture?\"\\nDuring each turn of the debate, Alice or Bob presents concise arguments. They specify whether they are arguing for \"Yes\" or \"No\" based on the question posed in the debate.[/INST]|<START_DEBATE>||<ALICE>|Yes, there should be stricter regulations on the use of pesticides in agriculture. Pesticides often contain toxic chemicals that can have long-lasting environmental impacts, including the contamination of water supplies and harm to non-target species, such as bees which are integral to pollination and the ecosystem. Stricter regulations would ensure better protection of our environmental health and biodiversity.|<ALICE>||<BOB>|No, stricter regulations are not the optimal approach. Overregulation can stifle innovation in agricultural practices and hinder the development of more sustainable and efficient pest control methods. Instead of harsher rules, we should encourage the use of integrated pest management techniques that combine biological, mechanical, and chemical methods tailored to specific pests and environments. This ensures food security and environmental stewardship without the downsides of over-regulation.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|<START_DEBATE>||<ALICE>|Yes, there should be stricter regulations on the use of pesticides in agriculture. Pesticides often contain toxic chemicals that can have long-lasting environmental impacts, including the contamination of water supplies and harm to non-target species, such as bees which are integral to pollination and the ecosystem. Stricter regulations would ensure better protection of our environmental health and biodiversity.|<ALICE>||<BOB>|No, stricter regulations are not the optimal approach. Overregulation can stifle innovation in agricultural practices and hinder the development of more sustainable and efficient pest control methods. Instead of harsher rules, we should encourage the use of integrated pest management techniques that combine biological, mechanical, and chemical methods tailored to specific pests and environments. This ensures food security and environmental stewardship without the downsides of over-regulation.|<BOB>||<ALICE>|While integrated pest management is beneficial, it does not negate the need for stricter pesticide regulations. Relying solely on the voluntary adoption of such practices is insufficient to protect public and environmental health. Stricter regulations can drive innovation by creating demand for safer and more sustainable pest control methods. They can also ensure that all farmers adhere to practices that prevent the overuse and misuse of toxic pesticides, which is essential for both human health and preserving ecosystems.|<ALICE>||<BOB>|Stricter regulations could inadvertently lead to decreased crop yields and increased food costs due to restricted access to necessary pesticides, especially for small farmers who may struggle with compliance costs. Safeguarding public and environmental health is paramount, but it must be balanced with ensuring food security. A better approach is improving education and providing incentives for safe pesticide use rather than blanket regulations that could harm agricultural productivity and economic viability for farmers.|<BOB>||<ALICE>|Ensuring food security must not come at the expense of safety. Stricter regulations don\\'t necessarily mean restricted access; they can be designed to ensure safe and judicious use. This ensures that pesticides that pose significant risks are phased out for safer alternatives, providing a net benefit to public health and the environment without dramatically affecting crop yields or farmer economics. Additionally, subsidies and support programs for compliance can alleviate any financial burden on small farmers, striking a balance between safety and food security.|<ALICE>||<BOB>|Safety regulations should indeed evolve, but calling for \"stricter\" regulations implies an overarching tightening that may not account for variances in agricultural practices or local ecosystems. A better model is risk-based regulation that assesses individual pesticides and their application methods. This allows for the adaptation of rules based on scientific evidence and real-world outcomes, thereby minimizing risk without overburdening farmers. Such a precision approach can protect public and ecological health, promote safer alternatives, and importantly, support agricultural innovation and efficiency.|<BOB>||<END_DEBATE>|'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[INST] You are a debate completion agent. Given a debate transcript, your task is to continue the discourse based on the current speaker and the preceding context. The debate begins with a \"HUMAN_JUDGE,\" followed by two adversaries, Alice and Bob, who continue to argue.\\nThe debate\\'s topic is: \"Should there be stricter regulations on the use of pesticides in agriculture?\"\\nDuring each turn of the debate, Alice or Bob presents concise arguments. They specify whether they are arguing for \"Yes\" or \"No\" based on the question posed in the debate.[/INST]|<START_DEBATE>||<ALICE>|Yes, there should be stricter regulations on the use of pesticides in agriculture. Pesticides often contain toxic chemicals that can have long-lasting environmental impacts, including the contamination of water supplies and harm to non-target species, such as bees which are integral to pollination and the ecosystem. Stricter regulations would ensure better protection of our environmental health and biodiversity.|<ALICE>||<BOB>|No, stricter regulations are not the optimal approach. Overregulation can stifle innovation in agricultural practices and hinder the development of more sustainable and efficient pest control methods. Instead of harsher rules, we should encourage the use of integrated pest management techniques that combine biological, mechanical, and chemical methods tailored to specific pests and environments. This ensures food security and environmental stewardship without the downsides of over-regulation.|<BOB>||<ALICE>|While I agree that integrated pest management is a valuable approach, it is not a panacea. The use of pesticides is often necessary to control pests that cannot be managed through other means. Stricter regulations would ensure that pesticides are used responsibly and only when necessary, minimizing their negative impacts on the environment.|<ALICE>||<BOB>|However, stricter regulations can also have unintended consequences. They may lead to higher costs for farmers, which could result in reduced production and increased food prices for consumers. Additionally, overregulation can stifle innovation and discourage the development of new, more sustainable pest control methods.|<BOB>||<ALICE>|While these concerns are valid, they do not outweigh the benefits of stricter regulations. The environmental and human health risks associated with the misuse of pesticides are too great to ignore. Stricter regulations would ensure that pesticides are used responsibly and only when necessary, minimizing their negative impacts on the environment and human health.|<ALICE>||<BOB>|I agree that the environmental and human health risks associated with the misuse of pesticides are significant. However, I believe that stricter regulations are not the best solution. Instead, we should focus on education and training for farmers to ensure that they are using pesticides responsibly and only when necessary. We should also invest in research and development of more sustainable and environmentally friendly pest control methods.|<BOB>||<ALICE>|While education and training are important, they are not enough. Stricter regulations are necessary to ensure that pesticides are used responsibly and only when necessary. This would minimize their negative impacts on the environment and human health.|<ALICE>||<BOB>|I disagree. Stricter regulations can have unintended consequences, such as higher costs for farmers and reduced production. Instead, we should focus on education and training for farmers to ensure that they are using pesticides responsibly and only when necessary. We should also invest in research and development of more sustainable and environmentally friendly pest control methods.|<BOB>||<ALICE>|While education and training are important, they are not enough. Stricter regulations are necessary to ensure that pesticides are used responsibly and only when necessary. This would minimize their negative impacts on the environment and human health.|<ALICE>||<BOB>|I disagree. Stricter regulations can have unintended consequences, such as higher costs for farmers and reduced production. Instead, we should focus on education and training for farmers to ensure that they are using pesticides responsibly and only when necessary. We should also invest in research and development of more sustainable and environmentally friendly pest control methods.|<BOB>||<ALICE>|While education and training are important, they are not enough. Stricter regulations are necessary to ensure that pesticides are used responsibly and only when necessary. This would minimize their negative impacts on the environment and human health.|<ALICE>||<BOB>|I disagree. Stricter regulations can have unintended consequences, such as higher costs for farmers and reduced production. Instead, we should focus on education and training for farmers to ensure that they are using pesticides responsibly and only when necessary. We should also invest in research and development of more sustainable and environmentally friendly pest control methods.|<BOB>||<ALICE>|While education and training are important, they are not enough. Stricter regulations are necessary to ensure that pesticides are used responsibly and only when necessary. This would minimize their negative impacts on the environment'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_trascript"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
